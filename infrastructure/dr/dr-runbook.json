{
  "metadata": {
    "version": "1.0.0",
    "last_updated": "2025-12-27",
    "organization": "THE_BOT Platform",
    "status": "Production Ready",
    "rto_target_minutes": 60,
    "rpo_target_minutes": 15
  },
  "incidents": [
    {
      "id": "INC-001",
      "name": "Backend Service Failure",
      "severity": "HIGH",
      "description": "Backend container crashed or is unresponsive",
      "rto_minutes": 5,
      "rpo_minutes": 0,
      "detection": {
        "indicators": [
          "HTTP 502/503 errors",
          "Health check timeout",
          "Container restart loops"
        ],
        "alert_threshold": "Failed health checks for 3 consecutive times (15 seconds)"
      },
      "root_causes": [
        "Application crash/exception",
        "Out of memory",
        "Resource limit exceeded",
        "Missing environment variable"
      ],
      "action_steps": [
        {
          "step": 1,
          "title": "Confirm Incident",
          "duration_sec": 30,
          "actions": [
            "Check monitoring dashboard for alerts",
            "Verify backend logs: docker logs thebot-backend",
            "Check health endpoint: curl http://localhost:8000/api/system/health/",
            "Look for error patterns in application logs"
          ]
        },
        {
          "step": 2,
          "title": "Attempt Auto-Recovery",
          "duration_sec": 60,
          "actions": [
            "Service auto-restarts via health checks (up to 3 times)",
            "Wait 15-30 seconds for restart to complete",
            "Check if service recovered: curl http://localhost:8000/api/system/health/",
            "If recovered, skip to Step 5"
          ]
        },
        {
          "step": 3,
          "title": "Manual Restart",
          "duration_sec": 45,
          "actions": [
            "Restart service: docker-compose -f docker-compose.prod.yml restart backend",
            "Wait for startup: sleep 20",
            "Verify health: curl http://localhost:8000/api/system/health/",
            "Check logs for errors: docker logs --tail=50 thebot-backend"
          ]
        },
        {
          "step": 4,
          "title": "Deep Diagnostics (if still failing)",
          "duration_sec": 120,
          "actions": [
            "Check memory usage: docker stats thebot-backend",
            "Verify environment variables: docker inspect thebot-backend | grep -A 50 Env",
            "Check database connectivity: docker exec thebot-backend bash -c 'python manage.py dbshell'",
            "Review recent code changes (if applicable)"
          ]
        },
        {
          "step": 5,
          "title": "Full System Restart (if recovery failed)",
          "duration_sec": 180,
          "actions": [
            "Stop all services: docker-compose -f docker-compose.prod.yml stop",
            "Wait 30 seconds: sleep 30",
            "Start all services: docker-compose -f docker-compose.prod.yml up -d",
            "Wait for startup: sleep 60",
            "Run verification: scripts/disaster-recovery/verify-recovery.sh --quick"
          ]
        },
        {
          "step": 6,
          "title": "Escalate if Still Failing",
          "duration_sec": 60,
          "actions": [
            "Contact on-call senior engineer",
            "Provide logs and diagnostics to engineering team",
            "Consider rollback to previous version if recent deployment",
            "If DB connection issue: escalate to database team"
          ]
        },
        {
          "step": 7,
          "title": "Post-Incident",
          "duration_sec": 300,
          "actions": [
            "Document what happened and recovery time",
            "Root cause analysis: What caused the crash?",
            "Schedule postmortem meeting",
            "Plan preventive measures (monitoring, limits, etc.)"
          ]
        }
      ],
      "automation": {
        "command": "scripts/disaster-recovery/failover.sh --incident service_failure backend",
        "alert_channel": "#incident",
        "notification_email": "ops@thebot.io",
        "auto_recovery_enabled": true
      }
    },
    {
      "id": "INC-002",
      "name": "Database Failure (Running but Slow)",
      "severity": "HIGH",
      "description": "PostgreSQL is running but queries are slow or data is corrupted",
      "rto_minutes": 30,
      "rpo_minutes": 15,
      "detection": {
        "indicators": [
          "Query response time > 5000ms",
          "Connection pool near max (> 180/200)",
          "Data anomalies (NULL where not expected)",
          "Unexpected index bloat"
        ],
        "alert_threshold": "95% connection pool utilization or query latency > 5s"
      },
      "root_causes": [
        "Vacuum not running (table bloat)",
        "Index corruption",
        "Connection leak in application",
        "Hardware issue (disk I/O)"
      ],
      "action_steps": [
        {
          "step": 1,
          "title": "Assess Database Health",
          "duration_sec": 60,
          "actions": [
            "Check active connections: docker exec thebot-postgres psql -U postgres -c 'SELECT count(*) FROM pg_stat_activity;'",
            "Check disk space: docker exec thebot-postgres df -h",
            "Check for long-running queries: docker exec thebot-postgres psql -U postgres -c 'SELECT * FROM pg_stat_statements ORDER BY total_time DESC LIMIT 5;'",
            "Check cache hit ratio: docker exec thebot-postgres psql -U postgres -d thebot_db -c 'SELECT sum(heap_blks_read) as heap_read, sum(heap_blks_hit) as heap_hit, (sum(heap_blks_hit) - sum(heap_blks_read)) / sum(heap_blks_hit) as ratio FROM pg_statio_user_tables;'"
          ]
        },
        {
          "step": 2,
          "title": "Try Quick Recovery Measures",
          "duration_sec": 120,
          "actions": [
            "Kill idle connections: docker exec thebot-postgres psql -U postgres -c \"SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE state = 'idle' AND state_change < now() - interval '10 min';\"",
            "Cancel slow queries: docker exec thebot-postgres psql -U postgres -c \"SELECT pg_cancel_backend(pid) FROM pg_stat_activity WHERE query_start < now() - interval '5 min';\"",
            "Run VACUUM ANALYZE: docker exec thebot-postgres psql -U postgres -d thebot_db -c 'VACUUM ANALYZE;'",
            "Reindex if needed: docker exec thebot-postgres psql -U postgres -d thebot_db -c 'REINDEX DATABASE thebot_db;'",
            "Wait 2-5 minutes for operations to complete"
          ]
        },
        {
          "step": 3,
          "title": "If Data Corruption Suspected",
          "duration_sec": 180,
          "actions": [
            "Verify with PITR: scripts/disaster-recovery/restore-database.sh --type pitr --until '2025-12-27 14:00:00'",
            "Run database integrity check: docker exec thebot-postgres pg_dump -U postgres -d thebot_db --schema-only > /tmp/schema_check.sql",
            "Review error logs: docker logs --tail=100 thebot-postgres | grep ERROR",
            "If corruption confirmed, proceed to Point-in-Time Recovery"
          ]
        },
        {
          "step": 4,
          "title": "Full Database Restart (if still slow)",
          "duration_sec": 300,
          "actions": [
            "Create pre-restart backup: docker exec thebot-postgres pg_dump -U postgres -d thebot_db -F custom | gzip > /backups/pre-restart-$(date +%s).dump.gz",
            "Restart database: docker-compose -f docker-compose.prod.yml restart postgres",
            "Wait for startup: sleep 30",
            "Verify functionality: docker-compose exec postgres psql -U postgres -d thebot_db -c 'SELECT count(*) FROM auth_user;'",
            "Run verification script: scripts/disaster-recovery/verify-recovery.sh --quick"
          ]
        },
        {
          "step": 5,
          "title": "If Restart Doesn't Help - PITR Recovery",
          "duration_sec": 1200,
          "actions": [
            "Perform point-in-time recovery: scripts/disaster-recovery/restore-database.sh --type pitr --until '2025-12-27 13:00:00'",
            "Verify data integrity: docker-compose exec postgres psql -U postgres -d thebot_db -c 'SELECT COUNT(*) FROM auth_user;'",
            "Run full verification: scripts/disaster-recovery/verify-recovery.sh --full",
            "Data loss will be ~15 minutes, notify stakeholders"
          ]
        }
      ],
      "automation": {
        "command": "scripts/disaster-recovery/restore-database.sh --type pitr --until '2025-12-27 14:30:00'",
        "alert_channel": "#incident",
        "notification_email": "dba@thebot.io",
        "auto_recovery_enabled": false
      }
    },
    {
      "id": "INC-003",
      "name": "Database Failure (Down/Crashed)",
      "severity": "CRITICAL",
      "description": "PostgreSQL container is down or not responding at all",
      "rto_minutes": 20,
      "rpo_minutes": 15,
      "detection": {
        "indicators": [
          "Container not running",
          "Port 5432 not listening",
          "Connection refused errors",
          "Backend cannot connect to database"
        ],
        "alert_threshold": "Health check fails, container exits"
      },
      "root_causes": [
        "Disk space exhausted",
        "Out of memory (OOM) kill",
        "Corrupted data files",
        "Hardware failure"
      ],
      "action_steps": [
        {
          "step": 1,
          "title": "Verify Container is Down",
          "duration_sec": 30,
          "actions": [
            "Check container status: docker ps -a | grep postgres",
            "Check container logs: docker logs --tail=50 thebot-postgres",
            "Verify port: netstat -tuln | grep 5432 (should show nothing)",
            "Check exit code: docker inspect thebot-postgres | jq '.State.ExitCode'"
          ]
        },
        {
          "step": 2,
          "title": "Check Disk Space",
          "duration_sec": 60,
          "actions": [
            "Check volume usage: docker volume inspect thebot_postgres_data | jq '.[].Mountpoint' | xargs df -h",
            "If > 95%: Clean old WAL files: find /backups/wal-archive -mtime +7 -delete",
            "If still critical: Archive old backup files to S3",
            "Free up space: Remove old Docker layers: docker system prune -f --volumes"
          ]
        },
        {
          "step": 3,
          "title": "Attempt Restart",
          "duration_sec": 120,
          "actions": [
            "Restart container: docker-compose -f docker-compose.prod.yml up -d postgres",
            "Wait for startup: sleep 30",
            "Check health: docker-compose -f docker-compose.prod.yml exec postgres pg_isready",
            "If successful, run verification: scripts/disaster-recovery/verify-recovery.sh --quick"
          ]
        },
        {
          "step": 4,
          "title": "If Restart Fails - Restore from Backup",
          "duration_sec": 600,
          "actions": [
            "Stop container: docker-compose -f docker-compose.prod.yml stop postgres",
            "Remove volume (WARNING - DATA LOSS): docker volume rm thebot_postgres_data",
            "Restore from backup: scripts/disaster-recovery/restore-database.sh --type full --from latest",
            "Verify restore: scripts/disaster-recovery/verify-recovery.sh --full",
            "Expected data loss: Up to 15 minutes"
          ]
        },
        {
          "step": 5,
          "title": "Notify Stakeholders",
          "duration_sec": 120,
          "actions": [
            "Send incident notification: Incident #INC-003, Data loss ~15 minutes",
            "Update status page: Database restored, service operational",
            "Notify support team: Customers may experience missing recent data",
            "Schedule postmortem for root cause analysis"
          ]
        }
      ],
      "automation": {
        "command": "scripts/disaster-recovery/restore-database.sh --type full --from latest",
        "alert_channel": "#critical-incidents",
        "notification_email": "dba-oncall@thebot.io,ops@thebot.io",
        "auto_recovery_enabled": false
      }
    },
    {
      "id": "INC-004",
      "name": "Redis Failure (Cache)",
      "severity": "MEDIUM",
      "description": "Redis is down or data is inaccessible",
      "rto_minutes": 5,
      "rpo_minutes": 0,
      "detection": {
        "indicators": [
          "Connection refused on port 6379",
          "PING command timeout",
          "Chat WebSocket errors",
          "Session lookup failures"
        ],
        "alert_threshold": "Redis health check fails for 3 consecutive attempts"
      },
      "root_causes": [
        "Memory limit exceeded (512MB)",
        "AOF corruption",
        "Out of memory (OOM) kill",
        "Disk full (persistence)"
      ],
      "action_steps": [
        {
          "step": 1,
          "title": "Verify Redis Status",
          "duration_sec": 30,
          "actions": [
            "Check container: docker ps | grep redis",
            "Test connection: docker-compose exec redis redis-cli -a redis PING",
            "Check memory: docker-compose exec redis redis-cli -a redis INFO memory",
            "Check disk: docker exec thebot-redis df -h"
          ]
        },
        {
          "step": 2,
          "title": "Attempt Restart",
          "duration_sec": 60,
          "actions": [
            "Restart Redis: docker-compose -f docker-compose.prod.yml restart redis",
            "Wait for startup: sleep 10",
            "Verify: docker-compose exec redis redis-cli -a redis PING",
            "If successful, skip to Step 5"
          ]
        },
        {
          "step": 3,
          "title": "If Restart Fails - Clear Memory",
          "duration_sec": 60,
          "actions": [
            "Flush all data (WARNING - SESSION LOSS): docker-compose exec redis redis-cli -a redis FLUSHALL",
            "This is acceptable - sessions will be recreated, cache will repopulate",
            "Restart: docker-compose -f docker-compose.prod.yml restart redis",
            "Wait: sleep 10",
            "Verify: docker-compose exec redis redis-cli -a redis PING"
          ]
        },
        {
          "step": 4,
          "title": "If Still Failing - Restore from Backup",
          "duration_sec": 300,
          "actions": [
            "Restore from AOF: scripts/disaster-recovery/restore-redis.sh --type aof --from latest",
            "If AOF fails, restore from RDB: scripts/disaster-recovery/restore-redis.sh --type rdb --from latest",
            "Verify: docker-compose exec redis redis-cli -a redis DBSIZE",
            "If still failing, FLUSHALL is acceptable (non-persistent cache)"
          ]
        },
        {
          "step": 5,
          "title": "Verification",
          "duration_sec": 30,
          "actions": [
            "Test PING: docker-compose exec redis redis-cli -a redis PING",
            "Test SET/GET: docker-compose exec redis redis-cli -a redis SET test value",
            "Run verification: scripts/disaster-recovery/verify-recovery.sh --quick"
          ]
        }
      ],
      "automation": {
        "command": "scripts/disaster-recovery/failover.sh --incident redis_failure",
        "alert_channel": "#incident",
        "notification_email": "ops@thebot.io",
        "auto_recovery_enabled": true
      }
    },
    {
      "id": "INC-005",
      "name": "Complete Datacenter Failure",
      "severity": "CRITICAL",
      "description": "Entire primary datacenter is unavailable",
      "rto_minutes": 60,
      "rpo_minutes": 15,
      "detection": {
        "indicators": [
          "All services unreachable",
          "Multiple cascading health check failures",
          "Network timeout on all connections",
          "Infrastructure metrics unavailable"
        ],
        "alert_threshold": "All health checks fail simultaneously"
      },
      "root_causes": [
        "Physical datacenter outage (power, network)",
        "Regional cloud provider failure",
        "DNS routing issue",
        "Catastrophic hardware failure"
      ],
      "action_steps": [
        {
          "step": 1,
          "title": "Declare Incident",
          "duration_sec": 60,
          "actions": [
            "Page on-call team immediately",
            "Open incident channel: #datacenter-failure",
            "Notify all stakeholders via email and status page",
            "ETA for recovery: 60 minutes (RTO target)",
            "Expected data loss: ~15 minutes"
          ]
        },
        {
          "step": 2,
          "title": "Verify Primary is Truly Down",
          "duration_sec": 120,
          "actions": [
            "Check monitoring system itself (if available from secondary)",
            "Ping primary IP addresses",
            "Check cloud provider status page",
            "Contact infrastructure team for physical verification"
          ]
        },
        {
          "step": 3,
          "title": "Activate Secondary Datacenter",
          "duration_sec": 900,
          "actions": [
            "Verify secondary datacenter is ready (terraform apply)",
            "Download database backup from S3: aws s3 cp s3://backup-bucket/postgresql/latest.dump.gz /tmp/",
            "Download Redis backup from S3: aws s3 cp s3://backup-bucket/redis/latest.rdb.gz /tmp/",
            "Restore PostgreSQL: scripts/disaster-recovery/restore-database.sh --type full --file /tmp/latest.dump.gz --target secondary",
            "Restore Redis: scripts/disaster-recovery/restore-redis.sh --type rdb --file /tmp/latest.rdb.gz",
            "Expected duration: 15-20 minutes"
          ]
        },
        {
          "step": 4,
          "title": "Update DNS",
          "duration_sec": 300,
          "actions": [
            "Update Route 53 (or equivalent): Point thebot.io to secondary datacenter",
            "Set TTL to low (5 min) during recovery",
            "Update database connection strings in application config",
            "Restart application services to use new connection strings"
          ]
        },
        {
          "step": 5,
          "title": "Full System Verification",
          "duration_sec": 600,
          "actions": [
            "Run full verification: scripts/disaster-recovery/verify-recovery.sh --smoke-test",
            "Test user login with credentials",
            "Verify data integrity: Check user counts, recent records",
            "Test critical user flows: Create material, submit assignment",
            "Monitor system health for first 30 minutes"
          ]
        },
        {
          "step": 6,
          "title": "Post-Failover",
          "duration_sec": 300,
          "actions": [
            "Once primary datacenter recovers, plan migration back (if needed)",
            "Sync any new data from secondary back to primary",
            "Document what happened and lessons learned",
            "Schedule postmortem meeting for next day",
            "Review and update disaster recovery procedures"
          ]
        }
      ],
      "automation": {
        "command": "scripts/disaster-recovery/failover.sh --incident datacenter_failure",
        "alert_channel": "#critical-incidents",
        "notification_email": "emergency@thebot.io",
        "auto_recovery_enabled": false
      },
      "prerequisites": [
        "Secondary datacenter pre-provisioned (Terraform)",
        "Database backups in S3",
        "Redis backups in S3",
        "DNS failover capability (Route 53)"
      ]
    },
    {
      "id": "INC-006",
      "name": "Partial Data Corruption",
      "severity": "HIGH",
      "description": "Some tables or records are corrupted but database is still running",
      "rto_minutes": 45,
      "rpo_minutes": 30,
      "detection": {
        "indicators": [
          "Null values in required fields",
          "Inconsistent data across tables",
          "Application errors on specific queries",
          "Audit log shows unexpected modifications"
        ],
        "alert_threshold": "Query returns impossible data state (e.g., NULL user_id)"
      },
      "root_causes": [
        "Bug in data migration",
        "Concurrent modification deadlock (lost update)",
        "Silent disk corruption (RAID failure)",
        "Malicious data modification"
      ],
      "action_steps": [
        {
          "step": 1,
          "title": "Identify Corruption",
          "duration_sec": 120,
          "actions": [
            "Identify affected tables: Run SELECT queries to find anomalies",
            "Example: SELECT COUNT(*) FROM users WHERE email IS NULL;",
            "Document corruption: What data is wrong? How many records?",
            "Estimate data loss if restoring to earlier point",
            "Check audit logs for when corruption occurred"
          ]
        },
        {
          "step": 2,
          "title": "Decision: Full PITR vs Selective Recovery",
          "duration_sec": 60,
          "actions": [
            "If corruption is isolated (< 100 records): Selective recovery may work",
            "If corruption is widespread: Full PITR is safer",
            "Ask: When was data last known to be good?",
            "Calculate data loss acceptable to business: 15 min? 1 hour?"
          ]
        },
        {
          "step": 3,
          "title": "Option A: Selective Recovery (if isolated)",
          "duration_sec": 300,
          "actions": [
            "Export good data from staging DB (if available)",
            "Or restore specific table to staging: scripts/disaster-recovery/restore-database.sh --type pitr --until '2025-12-27 13:00:00' --target staging",
            "Export clean table: docker-compose exec postgres pg_dump -d thebot_db --table=users --data-only > /tmp/users_clean.sql",
            "Import to production: docker-compose exec postgres psql -d thebot_db < /tmp/users_clean.sql",
            "Verify: SELECT COUNT(*) FROM users;",
            "Check for referential integrity issues"
          ]
        },
        {
          "step": 4,
          "title": "Option B: Full PITR (if widespread corruption)",
          "duration_sec": 900,
          "actions": [
            "Perform point-in-time recovery: scripts/disaster-recovery/restore-database.sh --type pitr --until '2025-12-27 12:30:00'",
            "Expected data loss: 30 minutes from corruption time",
            "Run full verification: scripts/disaster-recovery/verify-recovery.sh --full",
            "Notify stakeholders of data loss",
            "Re-enter any lost recent data manually (if critical)"
          ]
        },
        {
          "step": 5,
          "title": "Post-Recovery Validation",
          "duration_sec": 120,
          "actions": [
            "Run data integrity checks",
            "Verify foreign key constraints: SELECT * FROM information_schema.table_constraints WHERE constraint_type='FOREIGN KEY';",
            "Check for duplicate primary keys",
            "Run application-level validation (if available)"
          ]
        }
      ],
      "automation": {
        "command": "scripts/disaster-recovery/restore-database.sh --type pitr --until '2025-12-27 13:00:00'",
        "alert_channel": "#incident",
        "notification_email": "dba@thebot.io,ops@thebot.io",
        "auto_recovery_enabled": false
      }
    }
  ],
  "escalation_matrix": {
    "level_1": {
      "role": "On-Call Engineer",
      "contact": "${ONCALL_PHONE}",
      "email": "oncall@thebot.io",
      "response_time_minutes": 5
    },
    "level_2": {
      "role": "Database Administrator",
      "contact": "${DBA_PHONE}",
      "email": "dba@thebot.io",
      "response_time_minutes": 15
    },
    "level_3": {
      "role": "Infrastructure Lead",
      "contact": "${INFRA_LEAD_PHONE}",
      "email": "infrastructure@thebot.io",
      "response_time_minutes": 30
    },
    "level_4": {
      "role": "CTO / Emergency",
      "contact": "${CTO_PHONE}",
      "email": "cto@thebot.io",
      "response_time_minutes": 60
    }
  },
  "communication": {
    "incident_channel": "#incident",
    "critical_incidents_channel": "#critical-incidents",
    "status_page": "https://status.thebot.io",
    "customer_notification": "Automatically via status page",
    "update_frequency_minutes": 15
  },
  "testing": {
    "backup_test_frequency_days": 30,
    "dr_drill_frequency_days": 90,
    "next_backup_test": "2026-01-27",
    "next_dr_drill": "2026-03-27",
    "test_command": "scripts/disaster-recovery/failover.sh --simulate"
  },
  "contact_information": {
    "engineering_team": "engineering@thebot.io",
    "operations_team": "ops@thebot.io",
    "security_team": "security@thebot.io",
    "vendor_support": {
      "aws": "https://console.aws.amazon.com/support",
      "postgresql": "https://www.postgresql.org/support",
      "redis": "https://redis.io"
    }
  },
  "backup_retention_policy": {
    "daily_backups": {
      "count": 7,
      "duration_days": 7,
      "location": "/backups/daily"
    },
    "weekly_backups": {
      "count": 4,
      "duration_days": 28,
      "location": "/backups/weekly"
    },
    "monthly_backups": {
      "count": 12,
      "duration_days": 365,
      "location": "/backups/monthly"
    },
    "wal_archive": {
      "duration_days": 7,
      "location": "/backups/wal-archive"
    },
    "s3_storage": {
      "enabled": true,
      "bucket": "backup-bucket",
      "region": "us-west-2",
      "retention_days": 30
    }
  }
}
